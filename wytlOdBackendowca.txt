Dobra, to opowiem to tak, Å¼eby TwÃ³j frontendowiec od razu wiedziaÅ‚ â€co wchodzi, co wychodzi i gdzie to wsadziÄ‡â€ ğŸ˜„

---

## 1. OgÃ³lny obraz â€“ jak to dziaÅ‚a od strony usera

CaÅ‚y backend to *FastAPI* z kilkoma endpointami HTTP: /upload, /search, /gen/yn, /gen/mcq, /rate.

Flow z punktu widzenia aplikacji:

1. *User wrzuca pliki z materiaÅ‚ami* (PDF, PPTX, DOCX, EPUB) â†’ frontend robi POST /upload z plikami.
2. Backend:

   * czyta te pliki,
   * tnie tekst na kawaÅ‚ki (chunki),
   * robi embeddingi (sentence-transformers),
   * zapisuje wszystko w SQLite.
3. *User chce pytanie* â†’ frontend woÅ‚a:

   * POST /gen/mcq (pytanie ABCD) albo
   * POST /gen/yn (pytanie TAK/NIE),
     z tematem i poziomem trudnoÅ›ci.
4. Backend:

   * szuka najlepszych fragmentÃ³w tekstu pasujÄ…cych do tematu (RAG),
   * pyta model LLM â€wygeneruj pytanie na podstawie tych fragmentÃ³w i zwrÃ³Ä‡ czysty JSONâ€,
   * zapisuje pytanie + cytaty w bazie,
   * odsyÅ‚a do frontu gotowy JSON z pytaniem.
5. *User odpowiada w UI* â†’ frontend:

   * porÃ³wnuje odpowiedÅº usera z polem answer z backendu (ktÃ³rego na UI nie pokazuje od razu),
   * po pokazaniu odpowiedzi i wyjaÅ›nienia moÅ¼e wysÅ‚aÄ‡ ocenÄ™ pytania POST /rate (1â€“10, plus komentarz).

---

## 2. Konkretnie: endpointy i kontrakty dla frontu

### 2.1 /upload â€“ wrzucanie materiaÅ‚Ã³w

*Metoda:* POST /upload
*Body:* multipart/form-data z polem files (lista plikÃ³w).

PrzykÅ‚ad (pseudo):

const form = new FormData();
files.forEach(f => form.append("files", f));

fetch("http://localhost:8000/upload", {
  method: "POST",
  body: form,
});

*Response (JSON):*

{
  "ingested": [
    { "file": "WykÅ‚ad1.pdf", "chunks": 42 },
    { "file": "WykÅ‚ad2.pdf", "chunks": 37 }
  ]
}

Backend:

* wykrywa typ pliku,
* wyciÄ…ga tekst stron,
* tnie na chunki,
* robi embeddingi,
* zapisuje do tabel sources, chunks itd.

*Co ma zrobiÄ‡ frontend:*

* pozwoliÄ‡ uÅ¼ytkownikowi wybraÄ‡ kilka plikÃ³w,
* po wrzuceniu pokazaÄ‡ np. listÄ™ â€plik X â†’ Y chunkÃ³w w indeksieâ€.

---

### 2.2 /search â€“ podglÄ…d kontekstu (debug / przyszÅ‚e featury)

*Metoda:* POST /search
*Body (JSON):*

{
  "query": "sieci neuronowe",
  "k": 5
}

k â€“ ile najlepszych fragmentÃ³w ma zwrÃ³ciÄ‡.

*Response (JSON):*

{
  "results": [
    {
      "chunk_id": 123,
      "source_id": 1,
      "source": "WykÅ‚ad1.pdf",
      "page": 4,
      "quote": "SieÄ‡ neuronowa to model obliczeniowy inspirowany...",
      "text": "PeÅ‚ny tekst fragmentu ...",
      "score": 0.87
    },
    ...
  ]
}

*Co ma zrobiÄ‡ frontend:*

* To jest raczej narzÄ™dzie â€dla nasâ€ â€“ moÅ¼na zrobiÄ‡ np. zakÅ‚adkÄ™ debug:

  * input na zapytanie,
  * lista fragmentÃ³w z nazwÄ… pliku, stronÄ… i cytatem.

Nie jest konieczne do podstawowego dziaÅ‚ania quizu.

---

### 2.3 /gen/yn â€“ generowanie pytania TAK/NIE

*Metoda:* POST /gen/yn
*Body (JSON):*

{
  "topic": "uczenie nadzorowane",
  "difficulty": "medium"
}

topic jest opcjonalny, jak nie podasz, backend uÅ¼yje jakiegoÅ› ogÃ³lnego â€przeglÄ…d materiaÅ‚uâ€.

*Response (JSON):*

{
  "question_id": "uuid-1234-...",
  "question": {
    "kind": "YN",
    "stem": "Czy uczenie nadzorowane wymaga zestawu danych z etykietami?",
    "answer": "TAK",
    "explanation": "Uczenie nadzorowane korzysta z par (wejÅ›cie, etykieta) ...",
    "metadata": {
      "topic": "uczenie nadzorowane",
      "difficulty": "medium",
      "timestamp": "2025-11-24T12:34:56Z"
    },
    "citations": [
      {
        "source": "WykÅ‚ad1.pdf",
        "page": 5,
        "quote": "W uczeniu nadzorowanym zakÅ‚adamy dostÄ™p do danych z etykietami..."
      }
    ]
  }
}

*Co ma zrobiÄ‡ frontend:*

* ZapamiÄ™taÄ‡ question_id (przyda siÄ™ do ratingu).
* WyÅ›wietliÄ‡:

  * question.stem jako treÅ›Ä‡ pytania,
  * przyciski â€TAKâ€ / â€NIEâ€.
* *Nie pokazywaÄ‡* od razu pola answer ani explanation â€“ trzymasz to w stanie frontu.
* Po wybraniu odpowiedzi usera:

  * porÃ³wnujesz z question.answer,
  * pokazujesz, czy byÅ‚o dobrze,
  * wyÅ›wietlasz question.explanation i ewentualnie listÄ™ citations jako â€Å¹rÃ³dÅ‚aâ€.

---

### 2.4 /gen/mcq â€“ generowanie pytania ABCD

*Metoda:* POST /gen/mcq
*Body (JSON):* taki sam jak wyÅ¼ej (topic, difficulty).

*Response (JSON):*

{
  "question_id": "uuid-5678-...",
  "question": {
    "kind": "MCQ",
    "stem": "KtÃ³re stwierdzenie o perceptronie jest prawdziwe?",
    "options": [
      "a) Perceptron to jednokierunkowa sieÄ‡ neuronowa z jednÄ… warstwÄ… wyjÅ›ciowÄ….",
      "b) ...",
      "c) ...",
      "d) ..."
    ],
    "answer": "a",
    "explanation": "Perceptron ma jednÄ… warstwÄ™ wyjÅ›ciowÄ…, a...",
    "metadata": { "...": "..." },
    "citations": [ ... ]
  }
}

*Co ma zrobiÄ‡ frontend:*

* Znowu: trzymasz question_id.
* PokaÅ¼:

  * stem jako treÅ›Ä‡ pytania,
  * options jako listÄ™ przyciskÃ³w/RadioButtonÃ³w.
* answer jest np. "a" â€“ *ukrywasz* dopÃ³ki user nie kliknie odpowiedzi.
* Po wybraniu:

  * sprawdzasz, czy indeks/label odpowiedzi zgadza siÄ™ z answer,
  * pokazujesz wynik + explanation + ewentualne ÅºrÃ³dÅ‚a (citations).

---

### 2.5 /rate â€“ ocenianie jakoÅ›ci pytania

*Metoda:* POST /rate
*Body (JSON):*

{
  "question_id": "uuid-5678-...",
  "score": 9,
  "feedback": "Spoko pytanie, ale mogÅ‚oby byÄ‡ krÃ³tsze."
}

score jest normalizowany w backendzie do zakresu 1â€“10.

*Response (JSON):*

{ "ok": true }

Backend zapisuje ocenÄ™ w tabeli ratings i na jej podstawie podbija/obniÅ¼a wagi chunkÃ³w w chunk_weights, co wpÅ‚ywa na przyszÅ‚e wyszukiwanie (dobre fragmenty czÄ™Å›ciej trafiajÄ… do kontekstu, sÅ‚abe â€“ rzadziej).

*Co ma zrobiÄ‡ frontend:*

* Po pokazaniu poprawnej odpowiedzi moÅ¼esz wyÅ›wietliÄ‡ prosty slider / gwiazdki 1â€“10.
* Po wysÅ‚aniu /rate nie musisz nic wiÄ™cej â€“ backend ogarnia â€uczenie siÄ™â€.

---

## 3. Jak dziaÅ‚a AI / RAG â€pod maskÄ…â€ (Å¼eby kolega wiedziaÅ‚ co to robi, nie jak napisaÄ‡)

1. **Ingest plikÃ³w (/upload):**

   * Rozpoznanie formatu (PDF, PPTX, DOCX, EPUB) i wyciÄ…gniÄ™cie tekstu.
   * PociÄ™cie tekstu na kawaÅ‚ki (chunki) o dÅ‚ugoÅ›ci ~1100 znakÃ³w z overlapem 200, Å¼eby nie urwaÄ‡ zdaÅ„.
   * Dla kaÅ¼dego chunka liczy siÄ™ embedding wektorowy modelem sentence-transformers/all-MiniLM-L6-v2.
   * Wszystko lÄ…duje w SQLite: tabele sources, chunks.

2. **RAG search (rag_search):**

   * Gdy prosisz o pytanie z tematem "uczenie nadzorowane", backend najpierw embeduje to zapytanie tym samym modelem.
   * Liczy cosinus similarity z kaÅ¼dym chunkiem (mat @ qv).
   * Wynik mnoÅ¼y przez (1 + weight) gdzie weight bierze siÄ™ z ocen chunkÃ³w (chunk_weights). Dobre fragmenty majÄ… wiÄ™kszy wpÅ‚yw.
   * Zwraca top-k kontekstÃ³w â€“ to jest wejÅ›cie do LLM.

3. *LLM:*

   * gen_yes_no i gen_mcq robiÄ… prompt typu: â€UÅ¼yj wyÅ‚Ä…cznie poniÅ¼szych fragmentÃ³w i zwrÃ³Ä‡ JSON `{...}`â€.
   * Provider LLM jest wybierany przez settings.llm_provider (openai albo ollama, albo none â†’ wtedy fallback heurystyczny).
   * Frontend *nie musi tego ogarniaÄ‡* â€“ po prostu dostaje juÅ¼ gotowy JSON z pytaniem.

---

## 4. Co frontend musi ogarnÄ…Ä‡ praktycznie (checklista)

1. *Konfiguracja base URL* â€“ np. "http://127.0.0.1:8000" (jest w settings.host/port po stronie backendu).
2. *Ekran â€MateriaÅ‚yâ€:*

   * input type="file" z opcjÄ… wielu plikÃ³w,
   * POST /upload,
   * wyÅ›wietlenie info o zaindeksowanych plikach.
3. *Ekran â€Quizâ€:*

   * wybÃ³r typu pytania (YN / MCQ),
   * pole â€topicâ€ i drop difficulty,
   * request do /gen/yn lub /gen/mcq,
   * zapis question_id + question w stanie.
4. *Ekran pytania:*

   * wyÅ›wietlanie stem + odpowiednich opcji (TAK/NIE albo ABCD z options),
   * przy klikniÄ™ciu:

     * sprawdzenie odpowiedzi lokalnie vs answer,
     * pokazanie feedbacku + explanation + citations.
5. *Ekran ratingu:*

   * slider/gwiazdki 1â€“10,
   * po klikniÄ™ciu wysyÅ‚asz POST /rate z question_id + score + opcjonalnym feedback.

To tyle â€“ z frontu patrzysz na to jak na *prostÄ… API do generowania pytaÅ„ z JSON-em*, a caÅ‚a magia RAG + LLM + SQLite dzieje siÄ™ po drugiej stronie i nie musisz jej dotykaÄ‡ ğŸ’¾ğŸ§ 

Jak chcesz, mogÄ™ Ci jeszcze rozpisaÄ‡ gotowe typy w TypeScripcie (QuestionYN, QuestionMCQ, GenRequest, itp.), Å¼ebyÅ› mÃ³gÅ‚ je sobie wkleiÄ‡ do frontu.
